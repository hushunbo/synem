\section{Experiments}
We compared the accuracy of four matching functionals, CC, MI, EM and ECC, all of them driving the SyN transformation model. We selected the CC functional because its robustness and accuracy for mono-modal registration have been demonstrated in large scale comparative studies \cite{Klein2009, Klein2010, Rohlfing2012} (it would be desirable to reach similar performance in the multi-modal case), we would like to quantify how large is its drop in accuracy for multi-modal images. MI \cite{Maes1997, Mattes2003} may be considered the functional of choice for multi-modal registration, it is expected that any new developed functional yields results at least as good as MI. The EM functional \cite{Arce-santana2014} is, to the best of our knowledge, the most recent proposal for multi-modal registration based on the assumption of a functional relationship between image modalities. It introduces a measure of uncertainty for each intensity, which may help to alleviate the effects of non-stationary relationships between image intensities. We implemented the EM functional to drive the SyN transformation model and extended it to make it symmetric (to estimate both transfer functions instead of only one), in our experiments, these modifications performed significantly better than the basic functional (non-symmetric, and using an elastic transformation model) proposed by Arce {\it et al.}\cite{Arce-santana2014}. Both MI and EM are voxel-wise functionals (i.e. it compares pairs of single voxels), while CC and ECC are computed from local rectangular windows.

\subsection{Mono-modal registration}
Although our matching functional was designed for multi-modal image registration, it is important to first verify that the quality of the algorithms is reasonable for mono-modal registration. Figure \ref{fig:mono_graph_seg} show the average overlap score for each of 31 manually annotated anatomical regions from the IBSR database. Note that the Jaccard indices obtained with CC (i.e. ANTS) are higher than reported by Rohlfing \cite{Rohlfing2012}. In his experiments, he used three resolutions with a maximum of 10, 10 and 5 iterations only. Here, we set a maximum of 100, 100 and 25 iterations, leaving the rest of the parameters unchanged (the same for all functionals). We can see that both MI and EM are very competitive, but still not as good as CC. This may be explained by the fact that CC uses a window centered at each voxel for computing the similarity, while MI and EM are voxelwise. By considering neighborhoods of the same size, the performance of ECC is practically the same as CC. 
%Table \ref{tab:monomodal_results_segTri_fill} shows the overlap scores over tissue types (white matter, gray matter and cerebrospinal fluid), instead of anatomical areas.
%Table \ref{tab:monomodal_results_seg} and
%\input{monomodal_results_seg}
%\input{monomodal_results_segTri_fill}

\begin{figure*}[t!]
\centering
\includegraphics[width=1.0\linewidth]{./images/mono_lines_seg.png}\\
\caption{{\small Comparison of the registration performance (measured by the Jaccard index over 31 anatomical regions) of the Greedy SyN algorithm with EM, ECC, CC and MI metrics. The Jaccard indices were averaged over 306 monomodal registrations.}}
\label{fig:mono_graph_seg}\figcloser
\end{figure*}

\subsection{Multi-modal registration}\label{sec:multimodal_results}

To assess accuracy in the multi-modal case, we generated synthetic T2 images for all IBSR T1 images as follows. We first register the Brainweb T1 template (which plays the role of moving image) towards each IBSR T1 image (which play the role of fixed images) using ANTs with the CC metric (a mono-modal registration problem, where we know that ANTS with CC performs remarkably well). Then we applied the resulting deformation field to the Brainweb T2 template. The transfer function from the real T1 image to the warped T2 template is computed as the average T2 intensity associated to each T1 intensity. The computed transfer function is then applied to the real IBSR T1 image obtaining a ``perfectly aligned'' realistic synthetic T2 image for each IBSR volume, therefore the annotations remain exactly the same as the T1 counterparts and we are able to compute the overlap scores as before. Note that the number of registrations we need to perform is now 612 because we can use the T2 modality either as the moving or the fixed image. It is very important to note that, although the way we generate the semi-synthetic images may appear to be tailored towards our model (the so-called ``inverse crime''), this is not the case. Please note that intensities of each real image are transformed using a different transfer function, which maps intensities to each warped template. The warped templates are simply discarded afterwards, and not used for evaluation any more. Images from the same subject (real and synthetic) are never registered to each other during evaluation. Therefore, there will not exist, in general, any transfer function mapping intensities between any pair of images registered during validation. Figure \ref{fig:multi_seg} shows results similar to Figure \ref{fig:mono_graph_seg} but this time averaged over 612 multimodal registrations. Note how the performance of the CC metric strongly drops while EM, ECC and MI are less affected by the change of modality.\\

The Brainweb template also provides us with a simulation of a proton density (PD) image for the same brain anatomy. This allows us to repeat the procedure described above for each pair of three modalities, T1, T2 and PD. Figure \ref{fig:all_pairs_boxplots} depicts a summary of the results obtained over all pairs of modalities. For each pair of registered images, we compute the average Jaccard index of all anatomical regions. Each boxplot in Figure \ref{fig:all_pairs_boxplots} corresponds to the set of all 306 (mono-modal) or 612 (multi-modal) average scores for that particular method and that particular pair of modalities. We can observe that the CC metric performs very well for all mono-modal experiments (diagonal graphs), but it is severely affected in the multi-modal case (off-diagonal graphs). The ECC metric performs practically the same as CC in the mono-modal case, but is less affected in the multi-modal case.
%Table \ref{tab:multimodal_results_segTri_fill} shows the overlap scores of tissue types, where the same behavior can be observed.\\
%Table \ref{tab:monomodal_results_seg} and
%Table \ref{tab:multimodal_results_seg} and
%\begin{figure}[H]
%\centering
%    \includegraphics[width=\linewidth]{./images/semi_synthetic_image_creation.png}
%    \caption{{\small Semi-synthetic, manually annotated images for quantitative evaluation of multi-modal non-linear image registration algorithms.}}
%\label{fig:semi_synthetic_image_creation}
%\end{figure}
%\input{multimodal_results_seg}
%\input{multimodal_results_segTri_fill}

\begin{figure*}[t!]
\centering
\includegraphics[width=1.0\linewidth]{./images/multi_lines_seg.png}\\
\caption{{\small Comparison of the registration performance (measured by the Jaccard index over 31 anatomical regions) of the Greedy SyN algorithm with EM, ECC, CC and MI metrics. The Jaccard indices were averaged over 612 multimodal registrations.}}
\label{fig:multi_seg}\figcloser
\end{figure*}

\begin{figure}[t!]
\centering
    \includegraphics[width=\linewidth]{./images/all_modality_pairs_boxplots.png}
    \caption{{\small Distributions of average Jaccard indices for all pairs of available modalities (T1, T2 and PD). For each pair of registrations, we compute the average Jaccard index of all anatomical regions.}}
\label{fig:all_pairs_boxplots}\figcloser
\end{figure}

\subsection{$B_{0}$-T1 registration}
Quantitative results shown in previous section indicate that ECC and MI perform best for multi-modal registration. Fig. \ref{fig:comparison_B0_T1_coregistration} depicts a a $B_{0}$-T1 registration result obtained using ECC and MI. We can see from the level curves that the result obtained with ECC matches better the local structure of the T1. This behavior is explained by the fact that the ECC functional is computed over local windows rather than single voxel pairs. Since a realistic T1-$B_{0}$ template is not available, the validation methodology described in previous section cannot be used to validate $B_{0}$-T1 registration. Instead, we performed an indirect quantitative validation as follows. We first register the $B_{0}$ (moving) image towards each T1 (fixed) annotated image, obtaining diffeomorphisms $\phi_{i}$, $i=1,2,...,18$. Then, for every pair $\phi_{i}, \phi_{j}$, we compute the composition $\phi_{i,j}:=\phi_{i}\circ \phi_{j}^{-1}$ (which now maps two annotated T1 images). The resulting overlap score indirectly measures the (combined) accuracy of both transforms. Quantitative results of the indirect validation are depicted in fig. \ref{fig:indirect_validation_boxplots}. We can see that the average Jaccard index obtained with ECC is higher (and with lower variance) than using any of the other matching functionals, which also demonstrates the ECC robustness.
%\begin{figure}[p]
%\centering
%    \subfloat[Example $B_{0}$-T1 registration result using SyN with %ECC.]{\label{fig:epicor_b0up_ecc}\includegraphics[width=1.0\linewidth]{./images/T1B0Result/epicor_b0up_ecc.png}}\\
%    \subfloat[Example $B_{0}$-T1 registration result using SyN with MI.]{\label{fig:epicor_b0up_mi}\includegraphics[width=1.0\linewidth]{./images/T1B0Result/epicor_b0up_mi.png}}
%    \caption{{\small Example of a $B_{0}$-T1 registration result using SyN with ECC and MI. Level curves of the warped $B_{0}$ were overlaid on top of the (undeformed) T1 to %visually assess local structure agreement. Visually, level curves obtained with ECC have a better correspondence with the structure of the T1. This visual assessment is confirmed %quantitatively, as shown in fig. \ref{fig:indirect_validation_boxplots}.}}
%\label{fig:comparison_B0_T1_coregistration}
%\end{figure}


\begin{figure}[t!]
\centering
    \subfloat[]{\label{fig:epicor_b0up_ecc}\includegraphics[width=0.5\linewidth]{./images/T1B0Result/epicor_b0up_ecc_mi_slim.png}}
    \subfloat[]{\label{fig:indirect_validation_boxplots}\includegraphics[width=0.30\linewidth]{./images/T1B0Result/jaccard_boxplots_T1_B0_slim.png}}
    \caption{{\small $B_{0}$-T1 registration results. (a) Example result using SyN with ECC (top) and MI (bottom). Level curves of the warped $B_{0}$ were overlaid on top of the T1 to visually assess local structure agreement. Visually, level curves obtained with ECC have a better correspondence with the structure of the T1. (b) Visual assessment from panel (a) is confirmed by the quantitative results using the indirect validation procedure (see text).}}
\label{fig:comparison_B0_T1_coregistration}\figcloser
\end{figure}
%\begin{figure}[H]
%\centering
%    \includegraphics[width=\linewidth]{./images/T1B0Result/jaccard_boxplots_T1_B0.png}
%    \caption{{\small $B0$-T1 registration results using the indirect validation procedure (see text).}}
%\label{fig:indirect_validation_boxplots}
%\end{figure}

%\begin{figure}[H]
%\centering
%    \includegraphics[width=\linewidth]{./images/new_validation.png}
%    \caption{{\small Indirect validation protocol for $B_{0}$-T1 registration.}}
%\label{fig:indirect_validation}\figcloser
%\end{figure}


