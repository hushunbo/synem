\section{Introduction}
The human brain has been a subject of extensive research by the medical image community with a wide range of objectives, from practical clinical applications like disease diagnosis and surgical planning, to addressing scientific questions related to its structure and functionality. The goal of brain image registration is to compute a transformation that brings images of the brain into anatomical correspondence so that they can be jointly analyzed. A rough classification of volumetric image registration methods may be based on two main criteria: a) the deformation model (linear/non-linear), and b) the similarity measure (mono-modal/multi-modal). Registration of images from different modalities (\emph{multi-modal} image registration) is a specially challenging task, since an appropriate similarity metric is harder to define in the multi-modal case than in the \emph{mono-modal} case. Multi-modal image registration has traditionally been constrained to linear methods: since registration of medical images of different modalities is almost exclusively applied to intra-subject image registration, it is often believed that there must exist a linear transformation that correctly brings them into correspondence. However, certain imaging modalities present severe distortions that cannot be accommodated by a linear model. Diffusion MR images, for instance, suffer from distortions caused by $B_{0}$ susceptibility and eddy-currents \citep{Tournier2011, Andersson2003}. Figure \ref{fig:example_t1b0_problem} depicts an example of two B0 images and a T1 image from the same subject acquired in the same session. The noticeable geometric distortions in the B0 images are caused by differences in the magnetic susceptibility of different tissue types of the brain. These geometric distortions makes their registration to the T1 image (even being from the same subject), a non-linear problem if these artifacts are not corrected beforehand. Although several correction methods have been proposed to correct geometric distortions in EPI \citep{Andersson2003, Holland2010, Ruthotto, Irfanoglu2014}, most of them require at least two images acquired with opposite phase-encode blips. If the extra images with opposite phase-encode blips were not acquired, for example in data sets which were acquired without considering the need for correction, then the images cannot be corrected prior to registration with the T1. Despite the complexity of this registration task, it has a wide range of potential applications. Combining diffusion data with T1 MRI, for instance, has the potential of significantly improving tractography \citep{Smith2012, Girard2014}. Besides Diffusion MRI, the development of non-linear multimodal registration methods has the potential to impact other image modalities, like Functional MRI (which are also affected by susceptibility-induced geometric distortions), and intra-operative ultrasound images, which capture the deformation of the brain as a result of the brain surgery \citep{Rivaz2015, DeNigris2012}.

\begin{figure}[t!]
\centering
    \subfloat[]{\label{fig:T1B0_task_example_b0_up}\includegraphics[width=0.3\linewidth]{./images/T1B0Result/T1B0_task_example_b0_up.png}}
    \subfloat[]{\label{fig:T1B0_task_example_b0_down}\includegraphics[width=0.3\linewidth]{./images/T1B0Result/T1B0_task_example_b0_down.png}}
    \subfloat[]{\label{fig:T1B0_task_example_t1}\includegraphics[width=0.3\linewidth]{./images/T1B0Result/T1B0_task_example_t1.png}}
    \caption{Example T1-B0 images from the same subject. a),b) B0 image acquired with phase encode blips in the $+y$ and $-y$ direction, respectively. c) T1 image.}
\label{fig:example_t1b0_problem}
\end{figure}



\subsection{Multi-modal registration using information theoretic measures}
Existing multi-modal registration methods may be classified into two main approaches: 1) those that optimize information theoretic measures from the estimated joint probability distribution, 2) those that reduce the multi-modal problem to the mono-modal case. The most prominent example of metrics based in information theory is mutual information (MI) \citep{Maes1997, Mattes2003}. The success of MI is explained by its generality, since it does not assume the existence of a functional relationship between the intensities in the two modalities. This generality comes at the expense of disregarding any notion of proximity of intensity values: two intensities will be considered similar only if their estimated joint probability is high, no matter how close they are numerically, which may cause a large number of local maxima \citep[see][Fig. 2]{Roche1998}. In the standard formulation of MI, the joint probability distribution is estimated from the whole image ({\it i.e.}, it is a {\it global} metric), which makes the metric more robust to the effects of noise \citep{Mattes2003}. An important limitation of this kind of global metrics is precisely that the metric depends solely on the (globally) estimated probability distribution, which cannot capture non-stationary relationships between the image intensities \citep{Hermosillo2004}. Since the probability distributions relate point-wise intensity values (intensities of individual voxels), the metric is also insensitive to local image features that are important in non-linear registration like edges and texture \citep{Heinrich2012}. As pointed out by \cite{Sotiras2013}, any random spatial permutation of corresponding pixels would result in exactly the same distribution. A direct approach to tackle the problem of non-stationary intensity dependencies is to use locally estimated probability functions. \cite{Hermosillo2004}, for instance, uses Gaussian kernels centered at each voxel as weighting functions to reduce the contribution of far voxels to the local distribution. A limitation of this strategy, however, is its computational cost, as pointed out by \cite{Hermosillo2004}, since it results in a separate joint PDF estimation for each pixel, which makes it necessary to perform some simplifications and use parallel computing. Besides, as we reduce the number of local samples, the estimation becomes more sensitive to noise~\citep{Mattes2003}.

\subsection{Multi-modal registration by reduction to the mono-modal case}
Reducing the multi-modal problem to the mono-modal case may be accomplished by assuming the existence of a {\it transfer function} between the two modalities (a function that maps intensity values of one modality to corresponding intensities in the other). \cite{Roche2000} showed that, assuming the existence of a transfer function, a maximum-likelihood formulation of the registration problem is equivalent to maximization of the correlation ratio (CR). The main drawback of CR is precisely that it relies on the strong assumption of a functional dependency between the two modalities, which in general is not satisfied. However, experimental results have shown that this assumption is not critical for typical brain image registration tasks~\citep{Roche1998}. Being a global metric, CR shares the robustness to noise of MI but also the inability to capture non-stationary relationships between image intensities. However, one of the advantages of CR over MI is that it is sensitive to proximity of intensity values, which may help to reduce the number of local maxima \citep{Roche1998}. An additional advantage is that the CR metric can be computed efficiently from statistics from the images' iso-sets instead of explicitly estimating the joint distribution. Recently, \cite{Arce-santana2014} proposed a similar formulation of the registration problem which also makes the functional dependency assumption. In their work, the transfer function is modeled as a set of hidden random variables whose values can be estimated using the Expectation Maximization (EM) algorithm. Since the assumptions are similar to those made by \cite{Roche1998, Roche2000}, the resulting optimal transfer functions are the same. However, the resulting metric (which is also obtained by maximum-likelihood estimation) differs in that it introduces a measure of uncertainty in the estimated transfer function for each intensity value. This uncertainty appears in the metric as a weighting function that controls the contribution of each voxel intensity, and it helps to alleviate the effect of non-functional and non-stationary dependencies between the two modalities. One of the limitations of the original formulation proposed by \cite{Arce-santana2014} is that it is asymmetric (a limitation shared with the CR metric) in the sense that the transfer function to be estimated must be chosen beforehand (notice that there are in fact two transfer functions mapping intensities from one modality to the other), which may result in very different solutions. Another limitation is that \cite{Arce-santana2014} use an elastic deformation model \citep{Bajcsy1982, Gee1999}, and their optimization strategy consists in a Gauss-Newton iterative algorithm \citep{GVK502988711} that requires to solve a series of large systems of linear equations.

\subsection{Quantitative evaluation}
Besides developing deformation models and metrics, validation is one of the most challenging aspects in image registration. The most accepted validation methodologies, in the mono-modal case, consist in measuring the overlap of manually annotated anatomical regions \citep{Klein2009, Klein2010, Rohlfing2012}. These methodologies have made possible to quantitatively evaluate non-linear registration algorithms and compare their performance in a meaningful way. The Symmetric Normalization (SyN) algorithm developed by Avants {\it et al.}, and made available as part of the Advanced Normalization Tools (ANTS), has been extensively tested in large comparative studies using the aforementioned methodologies and has consistently been reported as one of the most accurate. For multi-modal images, the MI metric is implemented in ANTS, and can be used with SyN for diffeomorphic registration. However, to the best of our knowledge, there are no equivalent studies that quantitatively evaluate the accuracy of non-linear registration algorithms in the multi-modal case, and performance is assessed, in practice, only visually. The reason why validation becomes more challenging in the multi-modal case is that, as far as we know, there are no manually annotated multi-modal image sets publicly available.

\subsection{Summary of contributions}






