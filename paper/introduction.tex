\section{Introduction}
The human brain has been subject of extensive research by the medical image community with a wide range of objectives, from practical clinical applications like disease diagnosis and surgical planning, to addressing scientific questions related to its structure and functionality. The goal of brain image registration is to compute a transformation that brings images of the brain into anatomical correspondence so that they can be jointly analyzed. A rough classification of volumetric image registration methods (please refer to Sotiras {\it et al.} \cite{Sotiras2013} for a comprehensive survey) may be based on two main criteria: 1) the deformation model (linear/non-linear) and the matching criterion (mono-modal/multi-modal). Registration of images from different modalities (\emph{multi-modal} image registration) is a specially challenging task, since an appropriate matching criterion is harder to define in the multi-modal case than in the \emph{mono-modal} case \cite{Sotiras2013}. Multi-modal image registration has traditionally been constrained to linear methods: since registration of medical images of different modalities is almost exclusively applied to intra-subject image registration, it is often believed that there must exist a linear transformation that correctly brings them into correspondence. However, certain imaging modalities present severe distortions that cannot be accommodated by a linear model. Diffusion MR Images, for instance, suffer from distortions caused by $B_{0}$ susceptibility and eddy-currents \cite{Tournier2011}\cite{Andersson2003}, which makes their registration to other modality images, even from the same subject, a non-linear problem. Despite the complexity of the task, multi-modal image registration has a wide range of potential applications. Combining diffusion data to T1 MRI, for instance, has the potential of significantly improving tractography \cite{Smith2012}.\\

Existing multi-modal registration methods may be classified into two main approaches \cite{Sotiras2013}: 1) optimize information theoretic measures from the estimated joint probability distribution function, 2) reduce the multi-modal problem to a mono-modal problem. An important limitation of multi-modal methods based on the maximization of an information-theoretic similarity metric is precisely that the metric depends solely on the estimated distribution of corresponding intensities in both modalities, which is insensitive to local image features like edges and texture. As pointed out by Sotiras {\it et al.} \cite{Sotiras2013}, any random spatial permutation of corresponding pixels would
result in exactly the same distribution, which results in a large number of local maxima \cite{Roche1998}, making an accurate initialization crucial.\\

Many multi-modal image registration methods are extensions of the ideas developed for the mono-modal case. Hermosillo {\it et al.} \cite{Hermosillo2004} developed a general framework to extend existing methods for nonrigid mono-modal registration to the multi-modal case. Roche {\it et al.} \cite{Roche2004a} proposed an extension of the Demons algorithm to account for multi-modal images. They consider two types of transfer functions between the two modalities: functional dependency (each intensity in the first modality corresponds to one intensity in the other modality), and bi-functional dependency (each intensity in the first modality may correspond to two intensities in the other modality). Validation was performed using the Brainweb synthetic template \cite{Cocosco1997}\cite{Kwan1999} and two real images. Quantitative evaluation was performed by comparing
the resulting deformation fields, which only measures consistency across modalities but not registration accuracy.\\

One of the most important challenges in image registration is validation. The most accepted validation methodologies, in the mono-modal case, consist in measuring the overlap of manually annotated anatomical regions \cite{Klein2009}\cite{Klein2010}\cite{Rohlfing2012}. Validation becomes even more challenging in the multi-modal case since, to the best of our knowledge, there are no manually annotated multi-modal image sets publicly available. In this work, we propose two new methods for Multi-Modal Symmetric Diffeomorphic registration and a new validation protocol to quantitatively evaluate multi-modal image registration algorithms. Our contributions may be summarized as follows: 1) we adapted the EM framework for Multi-Modal Non-linear Registration proposed by Arce {\it et al.}\cite{Arce-santana2014} under the Symmetric Diffeomorphic Registration framework developed by Avants {\it et al.}\cite{Avants2008} \cite{Avants2011} and taking advantage of both image modalities (as oposed to \cite{Arce-santana2014} developed under the elastic deformation framework and one modality was arbitrarily chosen as reference), 2) we propose a new metric, called Expected Cross-Correlation, which extends the Cross-Correlation metric for multi-modal images by taking advantage of the estimated transfer functions, and 3)we propose a quantitative validation methodology for multi-modal brain MRI registration methods based on generating semi-synthetic images using real, manually annotated, mono-modal brain images and a synthetic multi-modal template.\\
